# 第一轮优化总结 (Round 1 Optimization Report)

> 目标：在不改动核心模型结构的前提下，提升“可用性、可观测性、可扩展性”和“为后续闭环学习铺路”的基础能力。

---
## 1. 优化项总览表（专业术语版 & 通俗解释）
| 编号 | 优化项 | 专业描述（专业术语） | 通俗解释（白话） | 直接收益 |
|------|--------|----------------------|------------------|-----------|
| 1 | 训练耗时控制 | 移除硬编码 200s 固定阻塞，改为参数化 `--sleep_after_layer`（默认 0） | 原来每层训练后都“傻等 200 秒”，现在不等了 | 训练更快，实验迭代提升 |
| 2 | 模型产物管理 | 增加 `--model_out` 自定义模型持久化路径，支持多版本模型共存 | 保存文件可以自己命名了 | 不会互相覆盖，方便对比 |
| 3 | 断点恢复 / 只评估模式 | 增加 `--resume` 加载已有权重；`--eval_only` 跳过训练执行推理验证 | 想看旧模型结果，不用重新训练 | 节省大量时间 |
| 4 | 单节点推理工具 | 新建 `predict_single.py` 支持对指定节点输出概率分布（Softmax） | 可以问“这个点预测多少信心” | 定位误判更具体 |
| 5 | 基础反馈记录 | `feedback_log.py` / `feedback_extended.py` 记录用户反馈（含证据、企业匹配、聚合计数） | 用户说“我被误判”现在能记下来 | 为后续“纠错学习”积累数据 |
| 6 | 反馈统计报表 | `feedback_stats.py` 汇总分布、争议节点、命中白名单比 | 一条命令看到“反馈情况” | 展示与监控更清晰 |
| 7 | 二次审核规则引擎雏形 | `second_review_rules.py` 按规则输出 `auto_correct / manual_queue / ignore` | 先用简单条件判断是否“要改判” | 有了“复核”雏形，不再拍脑袋 |
| 8 | 日志规范化 | 统一日志格式（时间 + 级别），支持 `--log_file` 输出到文件 | 日志整齐，可存档 | 排查与对比更方便 |
| 9 | 设备控制开关 | 增加 `--no_cuda` 参数，强制使用 CPU（调试友好） | GPU 出问题时不用改代码 | 降低调试摩擦 |
|10 | 训练进度可读性 | 进度条显示真实层数 `Layer x/总层数` + 早停触发提示 | 训练进展一眼能看懂 | 减少困惑，提高体验 |
|11 | 误判样本再利用准备 | 反馈扩展表结构预留 `used_for_retrain` 字段 | 以后可以用“纠错样本”再训练 | 铺路不停机迭代 |

---
## 2. 详细说明（专业 + 白话双列）
### 2.1 训练耗时控制
- 专业描述：消除固定阻塞式 `time.sleep(200)`，通过可配置参数实现非侵入式等待；默认零等待提升吞吐。
- 白话解释：以前代码强制“发呆 200 秒”，现在默认不浪费时间；真想暂停再手动加。

### 2.2 模型产物管理
- 专业：自定义模型输出路径使产物版本化，降低覆盖风险，利于多实验并行与回滚策略。
- 白话：可以有 `exp1.pth`、`exp2.pth`，互不影响。

### 2.3 断点恢复 / 只评估
- 专业：加入离线模型复用流程，分离训练阶段与推理阶段，提升可复现性与资源利用率。
- 白话：不用每次都重新训，节省时间。

### 2.4 单节点推理工具
- 专业：提供微粒度调试接口，支持节点级别置信度审计与目标样本解释链路接入。
- 白话：具体某个编号的点到底预测成啥，一查就知道。

### 2.5 基础反馈记录与结构化
- 专业：实现用户反馈事件的持久化与结构化存储（支持证据 JSON、企业命中标志、累积次数再计算），为后续主动学习与数据闭环奠定基础。
- 白话：有人说“这个是正常的”，我们有地方记了，还能累计次数。

### 2.6 反馈统计报表
- 专业：快速聚合多维反馈指标，输出分布、争议集合、白名单命中率等可观测性指标，便于优先级规划。
- 白话：一条命令看到“多少人反馈”“哪些最有争议”。

### 2.7 二次审核规则引擎（初版）
- 专业：基于启发式判定（企业白名单 + 低置信度、近期多次合法声明、主张冲突），输出审核决策类别，形成可迭代的 early policy layer。
- 白话：用几条简单规则决定“是不是要改判”或“要不要人工看”。

### 2.8 日志规范化
- 专业：统一日志结构化格式并支持多 handler，有利于日志采集、归档及后期可观测系统接入（ELK/Promtail）。
- 白话：日志现在整齐，能保存到文件里回头找。

### 2.9 设备控制开关
- 专业：可强制使用 CPU，规避 GPU 兼容/初始化失败导致的训练中断，提升调试稳定性。
- 白话：显卡坏了也能跑。

### 2.10 训练进度可读性
- 专业：准确的层级进度显示 + 早停触发提示 = 降低认知开销，提升监控效率。
- 白话：看到“现在第几层、第几轮、早停没”。

### 2.11 再训练字段预留
- 专业：在反馈数据结构中预留 `used_for_retrain` 标志，支持后续构建主动学习 / 纠错微调流水线。
- 白话：以后要把纠错样本拿来再训不用改结构。

---
## 3. 可验证改进的操作示例
| 验证目标 | 命令示例 | 预期观察 |
|----------|----------|----------|
| 训练不再强制等待 | `python main.py --dataset Sichuan --layers 1 --epochs 2` | 总时长不包含 200 秒空耗 |
| 自定义模型保存 | `python main.py --dataset Sichuan --model_out ./models/exp_demo.pth` | 生成指定文件名 |
| 断点评估 | `python main.py --dataset Sichuan --resume ./models/exp_demo.pth --eval_only` | 仅输出指标，无训练循环 |
| 单节点预测 | `python predict_single.py --dataset Sichuan --model ./models/exp_demo.pth --node_id 0` | 输出概率数组 |
| 写入扩展反馈 | 调用 `log_feedback_extended(...)` | `data/feedback_extended.csv` 追加一行 |
| 反馈统计 | `python feedback_stats.py --top 5` | 打印总数 / 争议节点 |
| 二次审核决策 | `python second_review_rules.py` 或手动调用 | 显示某节点决策状态 |
| 日志落盘 | 训练加 `--log_file train.log` | 生成日志文件 |

---
## 4. 初步“效果”衡量建议（可逐步补数据）
| 指标 | 类型 | 基线（填数字） | 当前（填数字） | 说明 |
|------|------|---------------|---------------|------|
| 单层训练平均耗时 (秒) | 性能 | (旧) | (新) | 对比去除 sleep 后下降幅度 |
| 复现评估时间 (秒) | 效率 | 需重新训练总耗时 | eval_only 耗时 | 体现加载复用价值 |
| 单节点分析响应时间 | 体验 | 不支持 | <1s | 支持即填“可用” |
| 反馈累计条数 | 数据积累 | 0 | N | 增长→有再训练基础 |
| 争议节点数 | 质量监控 | - | M | 判定修正关注面 |
| auto_correct 触发数 | 策略效果 | - | K | 评估策略价值 |

> 提示：可以把这些数字每周填一次，形成“趋势表”。

---
## 5. 当前尚未实现（后续路线）
| 计划项 | 状态 | 依赖 | 说明 |
|--------|------|------|------|
| 自动回填二次审核结果到反馈 CSV | 待做 | 已有规则 | 将决策写回 second_review_status / final_label |
| 增量再训练脚本（微调） | 待做 | 反馈纠错样本足够 | 用 `used_for_retrain=0` 样本构造微调集 |
| 漂移监控（分布 & AUC 滚动） | 待做 | 多次训练指标留存 | 发现性能下降趋势 |
| 趋势预测（区域/人群） | 待做 | 时间+区域字段 | 输出周期风险热力 |
| 主动学习（不确定性采样） | 待做 | 预测置信度批量缓存 | 降采样成本 |
| 注意力可解释输出 | 待做 | 保留 attention | 提供 TopK 邻居解释 |

---
## 6. 风险与控制
| 风险 | 描述 | 控制措施 |
|------|------|----------|
| 反馈数据被恶意投毒 | 大量伪造“合法” | 限制同来源频次 + 企业命中校验 |
| 再训练过拟合纠错样本 | 误报下降但召回跌 | 使用回放原始样本 + 低学习率 |
| 规则过度“放行” | 企业白名单不准确 | 增加有效期 + 来源可信级别 |
| 数据字段不完整 | 后续功能受阻 | 及早补齐时间戳、区域、用户群属性 |

---
## 7. 建议的第二轮优先事项（按投入/收益比）
1. 回填二次审核结果（产出真实 final_label）
2. 增量再训练脚手架（评估“纠错样本”价值）
3. 注意力 TopK 邻居导出（解释性）
4. 滚动指标日志化（便于画曲线）

---
## 8. TL;DR（给不看细节的人）
我们这轮不是“改算法”，而是：
- 让训练快 & 可复现
- 能查具体样本
- 能积累反馈数据
- 有了最初的“自动复核”雏形
- 后面想做纠错学习 / 预警分析不再是“从零开始”

> 下一步：把自动复核结果写回、做一次小规模纠错再训练，展示指标前后对比。

---
*文档生成时间：自动生成，可根据需要补充真实指标。*
