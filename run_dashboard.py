# run_dashboard.py - å®Œæ•´ä¿®å¤ç‰ˆå¯è§†åŒ–é¢æ¿
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import networkx as nx
import torch
import dgl
import numpy as np
import pandas as pd
import sys
import os
import pickle
import traceback

# === å®‰å…¨çš„è·¯å¾„è®¾ç½® ===
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# æ˜¾ç¤ºè·¯å¾„ä¿¡æ¯ç”¨äºè°ƒè¯•
debug_info = f"""
**è·¯å¾„è°ƒè¯•ä¿¡æ¯:**
- å½“å‰å·¥ä½œç›®å½•: `{os.getcwd()}`
- è„šæœ¬æ‰€åœ¨ç›®å½•: `{current_dir}`
- Pythonè·¯å¾„: `{sys.path[:3]}` 
"""

# å°è¯•å¯¼å…¥æ‚¨çš„æ¨¡å—
try:
    from model import GAT_COBO

    st.success("âœ… æˆåŠŸå¯¼å…¥ model.py")
    HAS_MODEL = True
except ImportError as e:
    st.error(f"âŒ å¯¼å…¥ model.py å¤±è´¥: {e}")
    HAS_MODEL = False

try:
    from utils import EarlyStopping, misclassification_cost, _set_cost_matrix, cost_table_calc, _validate_cost_matrix

    st.success("âœ… æˆåŠŸå¯¼å…¥ utils.py")
    HAS_UTILS = True
except ImportError as e:
    st.warning(f"âš ï¸ å¯¼å…¥ utils.py å¤±è´¥: {e}")
    HAS_UTILS = False


def load_graphs_dgl(bin_path):
    """æ›¿ä»£ load_graphs å‡½æ•°ï¼Œç›´æ¥ä½¿ç”¨ dgl.load_graphs"""
    try:
        if os.path.exists(bin_path):
            graph_list, graph_dict = dgl.load_graphs(bin_path)
            return graph_list, graph_dict
        else:
            st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}")
            return None, None
    except Exception as e:
        st.error(f"åŠ è½½å›¾æ•°æ®å¤±è´¥: {e}")
        return None, None


def load_info_pkl(pkl_path):
    """æ›¿ä»£ load_info å‡½æ•°"""
    try:
        if os.path.exists(pkl_path):
            with open(pkl_path, 'rb') as f:
                info = pickle.load(f)
            return info
        else:
            st.warning(f"ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {pkl_path}")
            return {}
    except Exception as e:
        st.error(f"åŠ è½½ä¿¡æ¯æ–‡ä»¶å¤±è´¥: {e}")
        return {}


def load_your_data():
    """åŠ è½½æ‚¨çš„å®é™…æ•°æ®"""
    data_loaded = False
    graph, features, labels = None, None, None

    # å°è¯•åŠ è½½ Sichuan æ•°æ®
    try:
        sichuan_bin_path = "./data/Sichuan_tele.bin"
        sichuan_pkl_path = "./data/Sichuan_tele.pkl"

        if os.path.exists(sichuan_bin_path):
            st.info("æ­£åœ¨åŠ è½½ Sichuan æ•°æ®é›†...")
            graph_list, _ = load_graphs_dgl(sichuan_bin_path)
            if graph_list and len(graph_list) > 0:
                graph = graph_list[0]
                features = graph.ndata['feat'].float() if 'feat' in graph.ndata else None
                labels = graph.ndata['label'] if 'label' in graph.ndata else None

                if features is not None and labels is not None:
                    data_loaded = True
                    st.success("âœ… æˆåŠŸåŠ è½½ Sichuan æ•°æ®é›†ï¼")

                    # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
                    info = load_info_pkl(sichuan_pkl_path)
                    if info:
                        st.write(f"æ•°æ®é›†ä¿¡æ¯: {info}")
        else:
            st.warning("Sichuan æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        st.error(f"åŠ è½½ Sichuan æ•°æ®å¤±è´¥: {e}")

    # å°è¯•åŠ è½½ BUPT æ•°æ®
    if not data_loaded:
        try:
            bupt_bin_path = "./data/BUPT_tele.bin"
            bupt_pkl_path = "./data/BUPT_tele.pkl"

            if os.path.exists(bupt_bin_path):
                st.info("æ­£åœ¨åŠ è½½ BUPT æ•°æ®é›†...")
                graph_list, _ = load_graphs_dgl(bupt_bin_path)
                if graph_list and len(graph_list) > 0:
                    graph = graph_list[0]
                    features = graph.ndata['feat'].float() if 'feat' in graph.ndata else None
                    labels = graph.ndata['label'] if 'label' in graph.ndata else None

                    if features is not None and labels is not None:
                        data_loaded = True
                        st.success("âœ… æˆåŠŸåŠ è½½ BUPT æ•°æ®é›†ï¼")
            else:
                st.warning("BUPT æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            st.error(f"åŠ è½½ BUPT æ•°æ®å¤±è´¥: {e}")

    return graph, features, labels, data_loaded


def load_demo_data():
    """å¦‚æœçœŸå®æ•°æ®åŠ è½½å¤±è´¥ï¼Œåˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    st.warning("ä½¿ç”¨æ¼”ç¤ºæ•°æ®è¿›è¡Œå±•ç¤º...")

    # åˆ›å»ºæ›´çœŸå®çš„æ¼”ç¤ºæ•°æ®
    num_nodes = 200
    num_edges = 800

    # åˆ›å»ºéšæœºå›¾ - ä½¿ç”¨æ›´çœŸå®çš„è¿æ¥æ¨¡å¼
    src_nodes = []
    dst_nodes = []

    # åˆ›å»ºä¸€äº›ç¤¾åŒºç»“æ„
    for community in range(4):
        start_node = community * 50
        end_node = (community + 1) * 50
        # ç¤¾åŒºå†…éƒ¨è¿æ¥
        for i in range(start_node, end_node):
            for j in range(i + 1, min(i + 5, end_node)):
                if np.random.random() < 0.3:
                    src_nodes.append(i)
                    dst_nodes.append(j)

    # æ·»åŠ ä¸€äº›è·¨ç¤¾åŒºè¿æ¥ï¼ˆå¼‚å¸¸æ¨¡å¼ï¼‰
    for _ in range(100):
        i = np.random.randint(0, num_nodes)
        j = np.random.randint(0, num_nodes)
        if abs(i - j) > 25:  # è·¨ç¤¾åŒºè¿æ¥
            src_nodes.append(i)
            dst_nodes.append(j)

    graph = dgl.graph((src_nodes, dst_nodes))

    # åˆ›å»ºæ›´çœŸå®çš„ç‰¹å¾
    features = torch.randn(num_nodes, 64)

    # åˆ›å»ºæ›´çœŸå®çš„æ ‡ç­¾ï¼ˆ10% çš„å¼‚å¸¸èŠ‚ç‚¹ï¼‰
    labels = torch.zeros(num_nodes, dtype=torch.long)
    anomaly_indices = np.random.choice(num_nodes, size=20, replace=False)
    labels[anomaly_indices] = 1

    graph.ndata['feat'] = features
    graph.ndata['label'] = labels

    return graph, features, labels


def show_network_statistics(graph, labels):
    """æ˜¾ç¤ºç½‘ç»œç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸ç”Ÿæˆå¤§å›¾ï¼‰"""
    col1, col2 = st.columns(2)

    with col1:
        # åº¦åˆ†å¸ƒ
        try:
            degrees = graph.in_degrees().numpy()
            fig = px.histogram(
                x=degrees,
                nbins=50,
                title="èŠ‚ç‚¹åº¦åˆ†å¸ƒ",
                labels={'x': 'åº¦', 'y': 'èŠ‚ç‚¹æ•°é‡'}
            )
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"åº¦åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")

    with col2:
        # æ ‡ç­¾åˆ†å¸ƒ
        try:
            label_counts = torch.bincount(labels).numpy()
            fig = px.pie(
                values=label_counts,
                names=['æ­£å¸¸', 'å¼‚å¸¸'],
                title="èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ",
                color_discrete_sequence=['blue', 'red']
            )
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"æ ‡ç­¾åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")

    # æ”¹è¿›çš„è¿é€šåˆ†é‡åˆ†æ
    try:
        # å¯¹å¤§å›¾ä½¿ç”¨é‡‡æ ·åˆ†æ
        if graph.number_of_nodes() > 1000:
            st.info("å›¾è¾ƒå¤§ï¼Œä½¿ç”¨é‡‡æ ·è¿›è¡Œè¿é€šåˆ†é‡åˆ†æ...")
            # éšæœºé‡‡æ ·1000ä¸ªèŠ‚ç‚¹è¿›è¡Œåˆ†æ
            sample_size = min(1000, graph.number_of_nodes())
            node_indices = np.random.choice(graph.number_of_nodes(), sample_size, replace=False)
            subgraph = dgl.node_subgraph(graph, node_indices)
            g_nx = dgl.to_networkx(subgraph.cpu())
        else:
            g_nx = dgl.to_networkx(graph.cpu())

        # è®¡ç®—è¿é€šåˆ†é‡
        if nx.is_directed(g_nx):
            components = list(nx.weakly_connected_components(g_nx))
        else:
            components = list(nx.connected_components(g_nx))

        component_sizes = [len(c) for c in components]

        col3, col4 = st.columns(2)
        with col3:
            if len(component_sizes) > 1:  # æœ‰å¤šä¸ªè¿é€šåˆ†é‡æ—¶æ‰æ˜¾ç¤ºåˆ†å¸ƒ
                fig = px.histogram(
                    x=component_sizes,
                    title="è¿é€šåˆ†é‡å¤§å°åˆ†å¸ƒ",
                    labels={'x': 'åˆ†é‡å¤§å°', 'y': 'æ•°é‡'}
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("å›¾æ˜¯å®Œå…¨è¿é€šçš„")

        with col4:
            st.metric("è¿é€šåˆ†é‡æ•°é‡", len(components))
            if component_sizes:
                st.metric("æœ€å¤§è¿é€šåˆ†é‡", max(component_sizes))
                st.metric("å¹³å‡åˆ†é‡å¤§å°", f"{np.mean(component_sizes):.1f}")
            else:
                st.metric("æœ€å¤§è¿é€šåˆ†é‡", 0)

    except Exception as e:
        st.warning(f"è¿é€šåˆ†é‡åˆ†æé‡åˆ°é—®é¢˜: {e}")


def create_safe_network_graph(graph, labels, max_nodes=500):
    """å®‰å…¨åˆ›å»ºç½‘ç»œå›¾ï¼Œé¿å…å¤§å›¾å¡æ­»"""
    try:
        # å¦‚æœå›¾å¤ªå¤§ï¼Œè¿›è¡Œé‡‡æ ·
        if graph.number_of_nodes() > max_nodes:
            st.warning(f"å›¾è¾ƒå¤§ï¼Œéšæœºé‡‡æ · {max_nodes} ä¸ªèŠ‚ç‚¹è¿›è¡Œæ˜¾ç¤º")
            node_indices = np.random.choice(graph.number_of_nodes(), max_nodes, replace=False)
            subgraph = dgl.node_subgraph(graph, node_indices)
            g_nx = dgl.to_networkx(subgraph.cpu())
            sampled_labels = labels[node_indices]
        else:
            g_nx = dgl.to_networkx(graph.cpu())
            sampled_labels = labels

        # ä½¿ç”¨å¿«é€Ÿå¸ƒå±€
        pos = nx.spring_layout(g_nx, k=1, iterations=15)

        # åˆ›å»ºè¾¹è½¨è¿¹ï¼ˆé™åˆ¶è¾¹æ•°é‡ï¼‰
        edge_x, edge_y = [], []
        edges = list(g_nx.edges())
        if len(edges) > 1000:
            edges = edges[:1000]
            st.info(f"æ˜¾ç¤ºå‰1000æ¡è¾¹ï¼ˆå…±{len(list(g_nx.edges()))}æ¡ï¼‰")

        for edge in edges:
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])

        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#888'),
            hoverinfo='none',
            mode='lines'
        )

        # åˆ›å»ºèŠ‚ç‚¹è½¨è¿¹
        node_x, node_y = [], []
        node_text = []
        node_color = []

        for node in g_nx.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            status = "å¼‚å¸¸" if sampled_labels[node] == 1 else "æ­£å¸¸"
            node_text.append(f'èŠ‚ç‚¹ {node}<br>çŠ¶æ€: {status}')
            node_color.append('red' if sampled_labels[node] == 1 else 'blue')

        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers',
            hoverinfo='text',
            text=node_text,
            marker=dict(
                size=8,
                color=node_color,
                line=dict(width=1, color='black')
            )
        )

        fig = go.Figure(data=[edge_trace, node_trace],
                        layout=go.Layout(
                            title='ç½‘ç»œæ‹“æ‰‘ç»“æ„ (è“è‰²:æ­£å¸¸, çº¢è‰²:å¼‚å¸¸)',
                            showlegend=False,
                            hovermode='closest',
                            margin=dict(b=20, l=5, r=5, t=40),
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))
                        )
        return fig

    except Exception as e:
        st.error(f"åˆ›å»ºç½‘ç»œå›¾æ—¶å‡ºé”™: {e}")
        # è¿”å›ä¸€ä¸ªç©ºçš„å›¾è¡¨
        return go.Figure()


def safe_get_degree(graph, node_id):
    """å®‰å…¨è·å–èŠ‚ç‚¹åº¦æ•°"""
    try:
        degree = graph.in_degrees(node_id)
        if hasattr(degree, 'item'):
            return degree.item()
        elif hasattr(degree, '__getitem__'):
            return degree[0] if len(degree) > 0 else 0
        else:
            return int(degree)
    except Exception as e:
        st.error(f"è®¡ç®—èŠ‚ç‚¹åº¦æ•°å¤±è´¥: {e}")
        return 0


def create_compatible_model_args(graph, features, labels, num_layers=1):
    """åˆ›å»ºä¸å±‚æ•°å…¼å®¹çš„æ¨¡å‹å‚æ•°"""
    num_feats = features.shape[1]
    n_classes = len(torch.unique(labels))

    # ç¡®ä¿n_classesè‡³å°‘ä¸º2
    if n_classes < 2:
        n_classes = 2

    # æ ¹æ®å±‚æ•°åˆ›å»ºåˆé€‚çš„headsåˆ—è¡¨
    if num_layers == 1:
        # å•å±‚æ¨¡å‹ï¼šåªéœ€è¦1ä¸ªæ³¨æ„åŠ›å¤´
        heads = [1]
    elif num_layers == 2:
        # ä¸¤å±‚æ¨¡å‹ï¼šéšè—å±‚å’Œè¾“å‡ºå±‚
        heads = [1, 1]
    else:
        # å¤šå±‚æ¨¡å‹ï¼šæ‰€æœ‰éšè—å±‚+è¾“å‡ºå±‚
        heads = [1] * num_layers + [1]

    model_args = {
        'g': graph,
        'num_layers': num_layers,
        'in_dim': num_feats,
        'num_hidden': 64,
        'num_classes': n_classes,
        'heads': heads,
        'activation': torch.nn.functional.elu,
        'dropout': 0.1,
        'dropout_adj': 0.3,
        'feat_drop': 0.1,
        'attn_drop': 0.1,
        'negative_slope': 0.2,
        'residual': False
    }

    return model_args


def load_and_run_model(graph, features, labels, device='cpu', num_layers=1):
    """åŠ è½½å¹¶è¿è¡ŒGAT-COBOæ¨¡å‹è¿›è¡Œæ¨ç†"""
    try:
        # åˆ›å»ºå…¼å®¹çš„æ¨¡å‹å‚æ•°
        model_args = create_compatible_model_args(graph, features, labels, num_layers)
        st.info(f"ä½¿ç”¨ {num_layers} å±‚æ¨¡å‹é…ç½®: heads={model_args['heads']}")

        # åˆ›å»ºæ¨¡å‹
        model = GAT_COBO(**model_args)
        model.to(device)
        model.eval()

        # å¦‚æœæœ‰ä¿å­˜çš„æ¨¡å‹æƒé‡ï¼Œå°è¯•åŠ è½½
        model_path = './models/gat_cobo_model.pth'
        if os.path.exists(model_path):
            try:
                model.load_state_dict(torch.load(model_path, map_location=device))
                st.success("âœ… åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹æƒé‡")
            except Exception as e:
                st.warning(f"âš ï¸ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
        else:
            st.info("â„¹ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–è¿›è¡Œæ¼”ç¤º")

        # è¿›è¡Œæ¨ç†
        with torch.no_grad():
            logits_inter_GAT, logits_inner_GAT, attention = model(features)

            # å®‰å…¨åœ°è®¡ç®—é¢„æµ‹ç»“æœ
            predictions = torch.softmax(logits_inter_GAT, dim=1)

            # å®‰å…¨åœ°è·å–å¼‚å¸¸åˆ†æ•° - æ£€æŸ¥ç»´åº¦
            if predictions.shape[1] >= 2:
                anomaly_scores = predictions[:, 1].cpu().numpy()  # å¼‚å¸¸ç±»åˆ«çš„æ¦‚ç‡
            else:
                # å¦‚æœåªæœ‰1ä¸ªç±»åˆ«ï¼Œä½¿ç”¨å…¶ä»–æ–¹æ³•
                anomaly_scores = predictions[:, 0].cpu().numpy()
                st.warning("æ¨¡å‹è¾“å‡ºåªæœ‰1ä¸ªç±»åˆ«ï¼Œä½¿ç”¨å”¯ä¸€ç±»åˆ«çš„æ¦‚ç‡ä½œä¸ºå¼‚å¸¸åˆ†æ•°")

            # è·å–é¢„æµ‹æ ‡ç­¾
            pred_labels = torch.argmax(logits_inter_GAT, dim=1).cpu().numpy()
            true_labels = labels.cpu().numpy()

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            accuracy = np.mean(pred_labels == true_labels)

            # å®‰å…¨è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
            true_positives = np.sum((pred_labels == 1) & (true_labels == 1))
            predicted_positives = np.sum(pred_labels == 1)
            actual_positives = np.sum(true_labels == 1)

            precision = true_positives / predicted_positives if predicted_positives > 0 else 0
            recall = true_positives / actual_positives if actual_positives > 0 else 0
            f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'anomaly_scores': anomaly_scores,
            'predictions': pred_labels,
            'attention_weights': attention,
            'performance': {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1_score
            },
            'model_outputs': {
                'logits_inter_GAT': logits_inter_GAT,
                'logits_inner_GAT': logits_inner_GAT
            }
        }

    except Exception as e:
        st.error(f"æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None


def visualize_attention_weights_safe(attention_weights, top_k=10):
    """å®‰å…¨åœ°å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡"""
    try:
        if attention_weights is None:
            return None

        # å®‰å…¨åœ°å¤„ç†æ³¨æ„åŠ›æƒé‡
        if isinstance(attention_weights, torch.Tensor):
            attention_weights = attention_weights.cpu()

        # è®¡ç®—å¹³å‡æ³¨æ„åŠ›æƒé‡
        if len(attention_weights.shape) == 3:  # [num_heads, num_nodes, num_nodes]
            avg_attention = attention_weights.mean(dim=0)  # å¹³å‡æ‰€æœ‰æ³¨æ„åŠ›å¤´
        else:
            avg_attention = attention_weights

        # æ£€æŸ¥ç»´åº¦
        if len(avg_attention.shape) != 2:
            st.warning(f"æ³¨æ„åŠ›æƒé‡ç»´åº¦å¼‚å¸¸: {avg_attention.shape}")
            return None

        num_nodes = avg_attention.shape[0]

        # é™åˆ¶åˆ†æè§„æ¨¡
        max_analysis_nodes = min(num_nodes, 100)  # æœ€å¤šåˆ†æ100ä¸ªèŠ‚ç‚¹

        attention_pairs = []

        for i in range(max_analysis_nodes):
            for j in range(max_analysis_nodes):
                if i != j:  # æ’é™¤è‡ªæ³¨æ„åŠ›
                    try:
                        attention_val = avg_attention[i, j].item()
                        attention_pairs.append({
                            'source': i,
                            'target': j,
                            'attention': attention_val
                        })
                    except:
                        continue

        # æŒ‰æ³¨æ„åŠ›æƒé‡æ’åºå¹¶å–å‰top_k
        if attention_pairs:
            attention_pairs.sort(key=lambda x: x['attention'], reverse=True)
            top_pairs = attention_pairs[:top_k]

            # åˆ›å»ºæŸ±çŠ¶å›¾
            sources = [f"{pair['source']}â†’{pair['target']}" for pair in top_pairs]
            attentions = [pair['attention'] for pair in top_pairs]

            fig = px.bar(
                x=attentions,
                y=sources,
                orientation='h',
                title=f"Top-{top_k} æ³¨æ„åŠ›æƒé‡æœ€é«˜çš„èŠ‚ç‚¹å¯¹",
                labels={'x': 'æ³¨æ„åŠ›æƒé‡', 'y': 'èŠ‚ç‚¹å¯¹ (æºâ†’ç›®æ ‡)'}
            )
            return fig
        else:
            st.info("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ³¨æ„åŠ›æƒé‡")
            return None

    except Exception as e:
        st.error(f"æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–å¤±è´¥: {e}")
        return None


def main():
    st.set_page_config(
        page_title="å›¾å¼‚å¸¸æ£€æµ‹å¯è§†åŒ–å¹³å°",
        page_icon="ğŸ§ ",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
    with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯", expanded=False):
        st.markdown(debug_info)
        st.write(f"model.py å­˜åœ¨: {os.path.exists(os.path.join(current_dir, 'model.py'))}")
        st.write(f"utils.py å­˜åœ¨: {os.path.exists(os.path.join(current_dir, 'utils.py'))}")
        st.write(f"dataç›®å½•å­˜åœ¨: {os.path.exists(os.path.join(current_dir, 'data'))}")

    # å°è¯•åŠ è½½çœŸå®æ•°æ®
    with st.spinner('æ­£åœ¨åŠ è½½æ•°æ®...'):
        real_graph, real_features, real_labels, data_loaded = load_your_data()

        if data_loaded:
            graph, features, labels = real_graph, real_features, real_labels
            data_source = "çœŸå®æ•°æ®"
        else:
            graph, features, labels = load_demo_data()
            data_source = "æ¼”ç¤ºæ•°æ®"

    # ä¾§è¾¹æ 
    st.sidebar.title("ğŸ›ï¸ æ§åˆ¶é¢æ¿")
    st.sidebar.info(f"æ•°æ®æº: {data_source}")

    # æ•°æ®é›†é€‰æ‹©
    dataset_options = ["Sichuan", "BUPT", "æ¼”ç¤ºæ•°æ®"]
    dataset = st.sidebar.selectbox("é€‰æ‹©æ•°æ®é›†", dataset_options)

    # å¯è§†åŒ–å‚æ•°
    st.sidebar.subheader("å¯è§†åŒ–è®¾ç½®")
    node_size = st.sidebar.slider("èŠ‚ç‚¹å¤§å°", 5, 20, 10)
    risk_threshold = st.sidebar.slider("é£é™©é˜ˆå€¼", 0.1, 1.0, 0.7, 0.05)

    # èŠ‚ç‚¹é€‰æ‹©
    selected_node = st.sidebar.number_input(
        "é€‰æ‹©èŠ‚ç‚¹ID",
        0,
        graph.number_of_nodes() - 1,
        0,
        key="node_selector"
    )

    # ä¸»ç•Œé¢
    st.title("ğŸ§  å›¾å¼‚å¸¸æ£€æµ‹äº¤äº’å¼åˆ†æå¹³å°")

    # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
    if data_loaded:
        st.success(f"âœ… å·²åŠ è½½çœŸå®æ•°æ® - èŠ‚ç‚¹æ•°: {graph.number_of_nodes()}, è¾¹æ•°: {graph.number_of_edges()}")
    else:
        st.warning("ğŸ”¶ ä½¿ç”¨æ¼”ç¤ºæ•°æ® - è¦ä½¿ç”¨çœŸå®æ•°æ®ï¼Œè¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨ ./data/ ç›®å½•ä¸‹")

    # æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ç½‘ç»œæ¦‚è§ˆ", "ğŸ” å¼‚å¸¸åˆ†æ", "ğŸ“ˆ ç»Ÿè®¡åˆ†æ", "ğŸ¤– æ¨¡å‹æ£€æµ‹"])

    with tab1:
        col1, col2 = st.columns([3, 1])

        with col1:
            st.subheader("ç½‘ç»œç»“æ„å¯è§†åŒ–")

            # æä¾›ä¸¤ç§å¯è§†åŒ–é€‰é¡¹
            viz_option = st.radio(
                "é€‰æ‹©å¯è§†åŒ–æ–¹å¼:",
                ["å¿«é€Ÿç»Ÿè®¡å›¾è¡¨", "äº¤äº’å¼ç½‘ç»œå›¾"],
                index=0
            )

            if viz_option == "å¿«é€Ÿç»Ÿè®¡å›¾è¡¨":
                show_network_statistics(graph, labels)
            else:
                if st.button("ç”Ÿæˆäº¤äº’å¼ç½‘ç»œå›¾", type="primary"):
                    with st.spinner("ç”Ÿæˆç½‘ç»œä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…..."):
                        fig = create_safe_network_graph(graph, labels)
                        if fig.data:  # æ£€æŸ¥å›¾è¡¨æ˜¯å¦æœ‰æ•°æ®
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.error("ç½‘ç»œå›¾ç”Ÿæˆå¤±è´¥ï¼Œè¯·å°è¯•å¿«é€Ÿç»Ÿè®¡å›¾è¡¨")

            # èŠ‚ç‚¹è¯¦æƒ…
            if st.button("æŸ¥çœ‹é€‰ä¸­èŠ‚ç‚¹è¯¦æƒ…", key="view_node_details"):
                st.subheader(f"èŠ‚ç‚¹ {selected_node} çš„è¯¦ç»†ä¿¡æ¯")
                col_a, col_b = st.columns(2)
                with col_a:
                    st.write("**åŸºæœ¬ä¿¡æ¯**")
                    st.write(f"- èŠ‚ç‚¹ID: {selected_node}")
                    st.write(f"- çœŸå®æ ‡ç­¾: {'å¼‚å¸¸' if labels[selected_node] == 1 else 'æ­£å¸¸'}")

                    # ä½¿ç”¨å®‰å…¨çš„åº¦è®¡ç®—
                    in_degree = safe_get_degree(graph, selected_node)
                    out_degree = safe_get_degree(graph, selected_node)  # ç®€åŒ–ï¼Œå®é™…åº”è¯¥è®¡ç®—å‡ºåº¦

                    st.write(f"- å…¥åº¦: {in_degree}")
                    st.write(f"- å‡ºåº¦: {out_degree}")

                with col_b:
                    st.write("**ç‰¹å¾ç»Ÿè®¡**")
                    node_feat = features[selected_node]
                    st.write(f"- ç‰¹å¾ç»´åº¦: {len(node_feat)}")
                    st.write(f"- ç‰¹å¾å‡å€¼: {node_feat.mean().item():.3f}")
                    st.write(f"- ç‰¹å¾æ ‡å‡†å·®: {node_feat.std().item():.3f}")

        with col2:
            st.subheader("ç½‘ç»œç»Ÿè®¡")
            st.metric("èŠ‚ç‚¹æ•°é‡", graph.number_of_nodes())
            st.metric("è¾¹æ•°é‡", graph.number_of_edges())
            anomaly_count = torch.sum(labels == 1).item()
            st.metric("å¼‚å¸¸èŠ‚ç‚¹", anomaly_count)
            st.metric("å¼‚å¸¸æ¯”ä¾‹", f"{(anomaly_count / len(labels)) * 100:.1f}%")

            st.subheader("é€‰ä¸­èŠ‚ç‚¹")
            st.write(f"èŠ‚ç‚¹ {selected_node}")
            st.write(f"æ ‡ç­¾: {'å¼‚å¸¸' if labels[selected_node] == 1 else 'æ­£å¸¸'}")

            # ä½¿ç”¨å®‰å…¨çš„åº¦è®¡ç®—
            degree = safe_get_degree(graph, selected_node)
            st.write(f"åº¦: {degree}")

    with tab2:
        st.subheader("å¼‚å¸¸æ£€æµ‹åˆ†æ")

        # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
        if st.button("ğŸš€ è¿è¡Œå¼‚å¸¸æ£€æµ‹", type="primary"):
            with st.spinner("æ£€æµ‹ä¸­..."):
                # æ›´çœŸå®çš„æ¨¡æ‹Ÿæ£€æµ‹è¿‡ç¨‹
                np.random.seed(42)

                # åŸºäºèŠ‚ç‚¹åº¦å’Œç‰¹å¾åˆ›å»ºæ›´çœŸå®çš„å¼‚å¸¸åˆ†æ•°
                degrees = graph.in_degrees().numpy()
                if len(degrees) > 0:
                    degree_factor = degrees / np.max(degrees)
                else:
                    degree_factor = np.zeros_like(degrees)

                # å¼‚å¸¸èŠ‚ç‚¹æœ‰æ›´é«˜çš„å¼‚å¸¸åˆ†æ•°
                base_scores = np.random.beta(2, 5, len(labels))
                anomaly_scores = base_scores.copy()

                # è®©çœŸå®å¼‚å¸¸èŠ‚ç‚¹å¾—åˆ†æ›´é«˜
                true_anomaly_indices = (labels == 1).numpy()
                if np.sum(true_anomaly_indices) > 0:
                    anomaly_scores[true_anomaly_indices] = np.random.beta(5, 2, np.sum(true_anomaly_indices))

                # åŠ å…¥åº¦çš„å½±å“
                anomaly_scores = 0.7 * anomaly_scores + 0.3 * degree_factor

                col1, col2 = st.columns(2)

                with col1:
                    # å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ
                    fig = px.histogram(
                        x=anomaly_scores,
                        nbins=30,
                        title="å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ",
                        labels={'x': 'å¼‚å¸¸åˆ†æ•°', 'y': 'èŠ‚ç‚¹æ•°é‡'}
                    )
                    fig.add_vline(x=risk_threshold, line_dash="dash", line_color="red")
                    fig.add_annotation(x=risk_threshold, y=5, text="é˜ˆå€¼", showarrow=True)
                    st.plotly_chart(fig, use_container_width=True)

                with col2:
                    # æ£€æµ‹æ€§èƒ½è¯„ä¼°
                    predictions = (anomaly_scores > risk_threshold).astype(int)
                    true_labels_np = labels.numpy()

                    accuracy = np.mean(predictions == true_labels_np)

                    # å®‰å…¨è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
                    true_positives = np.sum((predictions == 1) & (true_labels_np == 1))
                    predicted_positives = np.sum(predictions == 1)
                    actual_positives = np.sum(true_labels_np == 1)

                    precision = true_positives / predicted_positives if predicted_positives > 0 else 0
                    recall = true_positives / actual_positives if actual_positives > 0 else 0

                    st.metric("æ£€æµ‹å‡†ç¡®ç‡", f"{accuracy:.1%}")
                    st.metric("ç²¾ç¡®ç‡", f"{precision:.1%}")
                    st.metric("å¬å›ç‡", f"{recall:.1%}")

                    # é«˜é£é™©èŠ‚ç‚¹åˆ—è¡¨
                    high_risk_indices = np.where(anomaly_scores > risk_threshold)[0]
                    st.write(f"**å‘ç° {len(high_risk_indices)} ä¸ªé«˜é£é™©èŠ‚ç‚¹**")

                    if len(high_risk_indices) > 0:
                        risk_data = []
                        for idx in high_risk_indices[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                            risk_data.append({
                                'èŠ‚ç‚¹ID': idx,
                                'å¼‚å¸¸åˆ†æ•°': f"{anomaly_scores[idx]:.3f}",
                                'çœŸå®æ ‡ç­¾': labels[idx].item(),
                                'æ£€æµ‹ç»“æœ': 'æ­£ç¡®' if (anomaly_scores[idx] > risk_threshold) == (
                                            labels[idx] == 1) else 'é”™è¯¯'
                            })

                        st.dataframe(risk_data)

    with tab3:
        st.subheader("ç»Ÿè®¡åˆ†æ")

        col1, col2 = st.columns(2)

        with col1:
            # æ ‡ç­¾åˆ†å¸ƒ
            try:
                label_counts = torch.bincount(labels).numpy()
                fig = px.pie(
                    values=label_counts,
                    names=['æ­£å¸¸èŠ‚ç‚¹', 'å¼‚å¸¸èŠ‚ç‚¹'],
                    title="èŠ‚ç‚¹æ ‡ç­¾åˆ†å¸ƒ",
                    color_discrete_sequence=['blue', 'red']
                )
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"æ ‡ç­¾åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")

        with col2:
            # åº¦åˆ†å¸ƒ
            try:
                degrees = graph.in_degrees().numpy()
                fig = px.histogram(
                    x=degrees,
                    nbins=20,
                    title="èŠ‚ç‚¹åº¦åˆ†å¸ƒ",
                    labels={'x': 'èŠ‚ç‚¹åº¦', 'y': 'æ•°é‡'}
                )
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"åº¦åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")

        # ç‰¹å¾åˆ†æ
        st.subheader("ç‰¹å¾åˆ†æ")
        if st.button("åˆ†æç‰¹å¾åˆ†å¸ƒ"):
            try:
                feature_means = features.mean(dim=0).numpy()
                feature_stds = features.std(dim=0).numpy()

                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=list(range(len(feature_means))),
                    y=feature_means,
                    mode='lines+markers',
                    name='ç‰¹å¾å‡å€¼',
                    line=dict(color='blue')
                ))
                fig.add_trace(go.Scatter(
                    x=list(range(len(feature_means))),
                    y=feature_stds,
                    mode='lines+markers',
                    name='ç‰¹å¾æ ‡å‡†å·®',
                    line=dict(color='red')
                ))
                fig.update_layout(
                    title="ç‰¹å¾ç»Ÿè®¡åˆ†å¸ƒ",
                    xaxis_title="ç‰¹å¾ç»´åº¦",
                    yaxis_title="æ•°å€¼"
                )
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"ç‰¹å¾åˆ†æå¤±è´¥: {e}")

    with tab4:
        st.subheader("GAT-COBO æ¨¡å‹æ£€æµ‹")

        if HAS_MODEL:
            st.success("âœ… GAT-COBO æ¨¡å‹å¯ç”¨")

            # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
            st.info(
                f"æ•°æ®ä¿¡æ¯: {graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {features.shape[1]} ç»´ç‰¹å¾, {len(torch.unique(labels))} ä¸ªç±»åˆ«")

            # æ¨¡å‹é…ç½®é€‰é¡¹
            st.subheader("æ¨¡å‹é…ç½®")
            num_layers = st.selectbox("é€‰æ‹©ç½‘ç»œå±‚æ•°", [1, 2], index=0, key="model_layers")

            if st.button("ğŸš€ è¿è¡ŒGAT-COBOæ¨¡å‹æ£€æµ‹", type="primary", key="run_model"):
                with st.spinner("æ­£åœ¨è¿›è¡Œæ¨¡å‹æ¨ç†..."):
                    try:
                        # è¿è¡ŒçœŸå®æ¨¡å‹æ¨ç†
                        device = 'cuda' if torch.cuda.is_available() else 'cpu'
                        st.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

                        results = load_and_run_model(graph, features, labels, device, num_layers)

                        if results is not None:
                            st.success("âœ… æ¨¡å‹æ¨ç†å®Œæˆï¼")

                            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
                            perf = results['performance']
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("å‡†ç¡®ç‡", f"{perf['accuracy']:.1%}")
                            with col2:
                                st.metric("ç²¾ç¡®ç‡", f"{perf['precision']:.1%}")
                            with col3:
                                st.metric("å¬å›ç‡", f"{perf['recall']:.1%}")
                            with col4:
                                st.metric("F1åˆ†æ•°", f"{perf['f1_score']:.1%}")

                            # æ˜¾ç¤ºå¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ
                            st.subheader("å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ")
                            anomaly_scores = results['anomaly_scores']
                            fig = px.histogram(
                                x=anomaly_scores,
                                nbins=30,
                                title="GAT-COBOæ¨¡å‹è¾“å‡ºçš„å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ",
                                labels={'x': 'å¼‚å¸¸åˆ†æ•°', 'y': 'èŠ‚ç‚¹æ•°é‡'}
                            )
                            st.plotly_chart(fig, use_container_width=True)

                            # æ˜¾ç¤ºé«˜é£é™©èŠ‚ç‚¹
                            high_risk_threshold = st.slider("é«˜é£é™©é˜ˆå€¼", 0.1, 1.0, 0.7, 0.05,
                                                            key="high_risk_threshold")
                            high_risk_indices = np.where(anomaly_scores > high_risk_threshold)[0]

                            st.write(f"**å‘ç° {len(high_risk_indices)} ä¸ªé«˜é£é™©èŠ‚ç‚¹ (åˆ†æ•° > {high_risk_threshold})**")

                            if len(high_risk_indices) > 0:
                                risk_data = []
                                for idx in high_risk_indices[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                                    try:
                                        risk_data.append({
                                            'èŠ‚ç‚¹ID': idx,
                                            'å¼‚å¸¸åˆ†æ•°': f"{anomaly_scores[idx]:.3f}",
                                            'æ¨¡å‹é¢„æµ‹': 'å¼‚å¸¸' if results['predictions'][idx] == 1 else 'æ­£å¸¸',
                                            'çœŸå®æ ‡ç­¾': 'å¼‚å¸¸' if labels[idx] == 1 else 'æ­£å¸¸',
                                            'æ˜¯å¦ä¸€è‡´': 'âœ…' if results['predictions'][idx] == labels[idx] else 'âŒ'
                                        })
                                    except:
                                        continue

                                if risk_data:
                                    st.dataframe(risk_data)

                            # æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–
                            st.subheader("æ³¨æ„åŠ›æƒé‡åˆ†æ")
                            if st.checkbox("æ˜¾ç¤ºæ³¨æ„åŠ›æƒé‡å¯è§†åŒ–", key="show_attention"):
                                attention_fig = visualize_attention_weights_safe(
                                    results['attention_weights'], top_k=10
                                )
                                if attention_fig:
                                    st.plotly_chart(attention_fig, use_container_width=True)
                                else:
                                    st.info("æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–æš‚ä¸å¯ç”¨")

                        else:
                            st.error("âŒ æ¨¡å‹æ¨ç†å¤±è´¥")

                    except Exception as e:
                        st.error(f"æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

        else:
            st.warning("âš ï¸ GAT-COBO æ¨¡å‹ä¸å¯ç”¨")
            st.info("""
            è¦å¯ç”¨çœŸå®æ¨¡å‹æ£€æµ‹ï¼Œè¯·ç¡®ä¿ï¼š
            1. model.py æ–‡ä»¶å­˜åœ¨ä¸”åŒ…å« GAT_COBO ç±»
            2. æ‰€æœ‰ä¾èµ–é¡¹å·²æ­£ç¡®å®‰è£…  
            3. æ¨¡å‹å‚æ•°ä¸æ•°æ®åŒ¹é…
            """)


if __name__ == "__main__":
    main()